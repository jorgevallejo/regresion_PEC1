---
title: "Regresión, modelos y métodos"
subtitle: "Prueba de evaluación contínua 1"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
     toc: true
# pdf_document:
#   number_sections: true
# toc: true
# extra_dependencies: ["float"]
# urlcolor: blue
# header-includes:
#   - \renewcommand{\contentsname}{Índice}
# - \usepackage{float}

# Next code for knitting both types of documents automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
                    output_format = NULL,
                    output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

bibliography: references.bib
---
  
```{r setup, include=FALSE}
# knitr options

# Do not display code in output document
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center")
```

```{r estructura de directorios, results='hide', include=FALSE}
# 'data' contains raw source data.
# 'intermediateData' contains .RData objects with processed data.
# 'results' stores the final report files.

directories <- c("data", "results", "intermediateData", "images")

# Create directories
lapply(directories, function(x){
  if (!(dir.exists(x))){
    dir.create(x)
  }
})
```

```{r delete results files, eval= FALSE, include=FALSE}
# Run this chunk ONLY if you want to re-do
# the complete the report FROM THE ORIGINAL DATA.
# Remember that the .RData files are there to
# avoid unnecesarily redoing of long data processing.

directories <- c("results/", "intermediateData/", "images/")

file.remove(
  # Create a character vector of relative paths
  # to all files in the variable directories
  list.files(path = directories,
             all.files = TRUE,
             full.names = TRUE,
             recursive = TRUE)
)
```

```{r libraries, include=FALSE}
# Load packages
library(knitr)
library(tseries)
```

# Ejercicio 1. Estimación del peso del hígado

En este ejercicio vamos a trabajar con un set de datos recogidos [@chan2006estimating] de donantes de hígado con el que se quieren relacionar el peso estándar del hígado con las medidas de peso y altura. Las variables registradas son las siguientes:

-**gender:** Sexo del donante vivo de hígado.  
-**weight:** Peso del donante (kg).  
-**height:** Altura del donante (cm).  
-**liver_weight:** Peso estimado del hígado (g).  
-**liver_volume:** Volumen del hígado según la tomografía computarizada (ml).

Antes de ponernos a trabajar con los datos, es convenientes familiarizarnos con ellos para conocer su estructura y la distribución de datos en cada variable.

## Exploración de los datos

### Muestra de las primeras observaciones
```{r carga de datos}
# Load data
data <- read.csv("data/chan_data.csv")
head(data)
```

### Estructura

```{r estructura dataset}
str(data)
```

El set de datos está compuesto por 158 observaciones de 5 variables. De estas variables, cuatrto son númericas ( *weight, height, liver_weight* y *liver_volume* ) y una es categórica ( _gender_ ). Esta última contiene dos niveles ("F" y "M").

### Resumen numérico
```{r resumen numerico}
summary(data)
```

El resumen numérico nos ayuda a comparar la distribución de datos dentro de cada variable con lo que esperamos según la descripción de la variable. Específicamente, podemos usar el resumen para buscar valores anómalos (por ejemplo, cantidades negativas, o valores superiores a los máximos que pueden alcanzar los humanos). En este caso no parece haber nada que llame la atención al menos en las variables _weight_ y _height_, que a simple vista parecen respetar la distribución típica de humanos adultos. Las otras dos variables, *liver_weight* y *liver_volume*, son más difíciles de interpretar ya que no estamos familiarizados con ellas; aunque podemos decir que parecen seguir una distribución normal por el parecido entre media y mediana.

Un detalle interesante también es la relación entre diferentes niveles de la variable categórica, ya que podemos ver que en el set de datos hay el doble de observaciones correspondientes a mujeres que a hombres.

Otra utilidad del resumen es la detección de valores ausentes (codificados en R como NA). No aparece en ninguna de las variables, así que el set de datos es completo; no falta ningún valor en ninguna de las observaciones.


## Completar la base de datos con las variables derivadas ASC e IMC

El área de superficie corporal (ASC) la calcularemos, como en el paper original, según la fórmula de Du Bois [@du_bois_delafield_1916_1423319]:
$$
\log A = \log W \times 0.425 + \log H \times 0.725 + 71.84
$$

Siendo _A_ la superficie en centímetros cuadrados, _W_ el peso en kilogramos, y _H_ la altura en centímetros.

Asimismo también calcularemos el índice de masa corporal (IMC); que se averigua según la siguiente fórmula:
$$
IMC = W \text{(kg)}/H^2 \text{(m)}
$$
Midiéndose el IMC resultante en kg/m^2.

Calculamos las nuevas variables y las añadimos al set de datos con el siguiente código R:
```{r asc imc}
# Copy dataset
new_data <- data
# Add ASC
new_data[["ASC"]] <- exp(
  log(new_data[["weight"]]) * 0.425 + log(new_data[["height"]]) * 0.725 + 1.8564)
# Add IMC
new_data[["IMC"]] <- new_data[["weight"]]/(new_data[["height"]]/100)^2

head(new_data)
```


## Comprobar la normalidad de las variables peso y altura con el contraste de Jarque-Bera

El contraste de Jarque-Bera es un ensayo de normalidad que determina si los datos muestrales tienen la asimetría y curtosis de una distribución normal. 

Como hipótesis nula estableceremos que la asimetría y curtosis de la variable son iguales a las de la distribución normal. 

Como hipótesis alternativa entenderemos lo contrario, que la asimetría o la curtosis de la variable no son iguales a las de una distribución normal.

Emplearemos un nivel de significatividad del 5%.

Para realizar el test usaremos la función `jarque.bera.test()` disponible en el paquete `tseries`:
```{r jarque bera test}
# Peso
jarque.bera.test(new_data[["weight"]])
```
```{r}
# Altura
jarque.bera.test(new_data[["height"]])
```

En ninguno de los dos casos obtenemos p-valores por debajo de 0.05, por lo que **no podemos rechazar la hipótesis nula** de cada variable de seguir la distribución normal.


## Búsqueda de outliers para peso y altura

Un outlier es una observación que no se ajusta bien al modelo con el que estamos trabajando. Existen métodos estadísticos para localizarlos, pero el modo más intuitivo cuando trabajamos con pocas dimensiones es representando las observaciones en gráficas:

```{r}
# Construme modelo altura-peso
mod_altura_peso <-lm(new_data[["weight"]] ~ new_data[["height"]])

# Genera grafica
plot(new_data[, c("height", "weight")],
     col = ifelse(new_data$height < 155 & new_data$weight > 70, "red", "black"),
     xlab = "Peso", ylab = "Altura"
)
abline(mod_altura_peso,
       col = "blue")
outlier <- new_data[new_data$height < 155 & new_data$weight > 70,]
text(x = ceiling(outlier$height +1),
     y = ceiling(outlier$weight +1),
     labels = rownames(outlier))
```

Parece haber un correlación positiva entre peso y altura, distribuyéndose las observaciones en la gráfica siguiendo una diagonal más o menos marcada (hemos añadido la línea de regresión en color azul para mayor claridad). Sin embargo observamos un sujeto en la zona superior izquierda, remarcado en rojo, llamativamente alejado del resto. ESto es, para su altura presenta un peso muy superior al que esperamos dentro de la muestra.


Si preferimos utilizar métodos numéricos, podemos estudentizar los resíduos y examinar los mayores de entre ellos (_jacknife or crossvalidated residuals_):

```{r}
stud <- rstudent(mod_altura_peso)
head(sort(abs(stud), decreasing = TRUE))
```

Vemos que la observación con mayor residuo estudentizado coincide con la que habíamos detectado en el gráfico. ¿Pero la clasificaríamos realmente como un outlier? Si calculamos el valor crítico de Bonferroni para $\alpha$ = 0.05:
```{r}
n <- nrow(new_data) # Size
p <- 2              # Dimensions
(vc <- abs(qt(0.05/(n*2), (n-p-1)))) # Critical value (absolute) 
```

Vemos que, efectivamente, el valor absoluto de la observación 126 es mayor que el valor absoluto del valor crítico corregido por Bonferroni y numéricamente lo consideraríamos un outlier.

Si queremos representar este test gráficamente:

```{r}
plot(stud, type = 'h',
     main="Outliers por valor crítico",
     xlab = "Observaciones",
     ylab = "Residuos estudentizados")
abline(h= vc, col = "red")
abline(h = 0)
abline(h = -vc, col = "red")
```

Sin embargo, aunque hayamos definido ese valor como un _outlier_ no sabemos si aparece en la muestra por alguna razón anómala (p.e. error al codificar las medidas) o si realmente ese tipo de valores existen en la población a estudiar, así que no lo eliminaremos. Tampoco hemos comprobado si ese valor único ejerce una influencia desproporcionada en los resultados de la regresión.








<!-- # Apéndice A: Código -->

<!-- El documento original en formato .Rmd, que incluye el código completo en lenguaje R usado para generar este informe, se puede consultar y descargar en el siguiente repositorio de Github: -->
<!-- [jorgevallejo/RNAseq_analysis_PEC2](https://github.com/jorgevallejo/RNAseq_analysis_PEC2) -->

<!-- # Apéndice B: Reproducibilidad {#apendiceB} -->
<!-- ```{r session_info, include=TRUE, echo=TRUE, results='markup'} -->
<!-- sessionInfo() # For better reproducibility -->
<!-- ``` -->


# Referencias