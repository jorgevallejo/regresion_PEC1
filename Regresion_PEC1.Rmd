---
title: "Regresión, modelos y métodos"
subtitle: "Prueba de evaluación contínua 1"
author: "Jorge Vallejo Ortega"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
     toc: true
# pdf_document:
#   number_sections: true
# toc: true
# extra_dependencies: ["float"]
# urlcolor: blue
# header-includes:
#   - \renewcommand{\contentsname}{Índice}
# - \usepackage{float}

# Next code for knitting both types of documents automatically comes from https://stackoverflow.com/questions/39662365/knit-one-markdown-file-to-two-output-files/53280491#53280491
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
                    output_format = NULL,
                    output_dir = "results") })
# And:
# https://stackoverflow.com/a/46007686/10647267

bibliography: references.bib
---
  
```{r setup, include=FALSE}
# knitr options

# Do not display code in output document
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center")
```

```{r estructura de directorios, results='hide', include=FALSE}
# 'data' contains raw source data.
# 'intermediateData' contains .RData objects with processed data.
# 'results' stores the final report files.

directories <- c("data", "results", "intermediateData", "images")

# Create directories
lapply(directories, function(x){
  if (!(dir.exists(x))){
    dir.create(x)
  }
})
```

```{r delete results files, eval= FALSE, include=FALSE}
# Run this chunk ONLY if you want to re-do
# the complete the report FROM THE ORIGINAL DATA.
# Remember that the .RData files are there to
# avoid unnecesarily redoing of long data processing.

directories <- c("results/", "intermediateData/", "images/")

file.remove(
  # Create a character vector of relative paths
  # to all files in the variable directories
  list.files(path = directories,
             all.files = TRUE,
             full.names = TRUE,
             recursive = TRUE)
)
```

```{r libraries, include=FALSE}
# Load packages
library(knitr)
library(tseries)
library(faraway)
library(car)
library(MASS)
```

# Ejercicio 1. Estimación del peso del hígado

En este ejercicio vamos a trabajar con un set de datos recogidos [@chan2006estimating] de donantes de hígado con el que se quieren relacionar el peso estándar del hígado con las medidas de peso y altura. Las variables registradas son las siguientes:

-**gender:** Sexo del donante vivo de hígado.  
-**weight:** Peso del donante (kg).  
-**height:** Altura del donante (cm).  
-**liver_weight:** Peso estimado del hígado (g).  
-**liver_volume:** Volumen del hígado según la tomografía computarizada (ml).

Antes de ponernos a trabajar con los datos, es convenientes familiarizarnos con ellos para conocer su estructura y la distribución de datos en cada variable.

## Exploración de los datos

### Muestra de las primeras observaciones
```{r carga de datos}
# Load data
data <- read.csv("data/chan_data.csv")
head(data)
```

### Estructura

```{r estructura dataset}
str(data)
```

El set de datos está compuesto por 158 observaciones de 5 variables. De estas variables, cuatrto son númericas ( *weight, height, liver_weight* y *liver_volume* ) y una es categórica ( _gender_ ). Esta última contiene dos niveles ("F" y "M").

### Resumen numérico
```{r resumen numerico}
summary(data)
```

El resumen numérico nos ayuda a comparar la distribución de datos dentro de cada variable con lo que esperamos según la descripción de la variable. Específicamente, podemos usar el resumen para buscar valores anómalos (por ejemplo, cantidades negativas, o valores superiores a los máximos que pueden alcanzar los humanos). En este caso no parece haber nada que llame la atención al menos en las variables _weight_ y _height_, que a simple vista parecen respetar la distribución típica de humanos adultos. Las otras dos variables, *liver_weight* y *liver_volume*, son más difíciles de interpretar ya que no estamos familiarizados con ellas; aunque podemos decir que parecen seguir una distribución normal por el parecido entre media y mediana.

Un detalle interesante también es la relación entre diferentes niveles de la variable categórica, ya que podemos ver que en el set de datos hay el doble de observaciones correspondientes a mujeres que a hombres.

Otra utilidad del resumen es la detección de valores ausentes (codificados en R como NA). No aparece en ninguna de las variables, así que el set de datos es completo; no falta ningún valor en ninguna de las observaciones.


## 1a. Completar la base de datos con las variables derivadas ASC e IMC

El área de superficie corporal (ASC) la calcularemos, como en el paper original, según la fórmula de Du Bois [@du_bois_delafield_1916_1423319]:
$$
\log A = \log W \times 0.425 + \log H \times 0.725 + 0.007184
$$

Siendo _A_ la superficie en metros cuadrados, _W_ el peso en kilogramos, y _H_ la altura en centímetros. Para la constante hemos usado 0.007184 en lugar de 71.84 (de la fórmula original de Du Bois) para que el resultado estén en metros cuadrados.

Asimismo también calcularemos el índice de masa corporal (IMC); que se averigua según la siguiente fórmula:
$$
IMC = W \text{(kg)}/H^2 \text{(m)}
$$
Midiéndose el IMC resultante en kg/m^2.

Calculamos las nuevas variables y las añadimos al set de datos con el siguiente código R:
```{r asc imc}
# Copy dataset
new_data <- data
# Add ASC
new_data[["ASC"]] <- exp(
  log(new_data[["weight"]]) * 0.425 + log(new_data[["height"]]) * 0.725 + log(0.007184))
# Add IMC
new_data[["IMC"]] <- new_data[["weight"]]/(new_data[["height"]]/100)^2

head(new_data)
```


## 1b. Comprobar la normalidad de las variables peso y altura con el contraste de Jarque-Bera

El contraste de Jarque-Bera es un ensayo de normalidad que determina si los datos muestrales tienen la asimetría y curtosis de una distribución normal. 

Como hipótesis nula estableceremos que la asimetría y curtosis de la variable son iguales a las de la distribución normal. 

Como hipótesis alternativa entenderemos lo contrario, que la asimetría o la curtosis de la variable no son iguales a las de una distribución normal.

Emplearemos un nivel de significatividad del 5%.

Para realizar el test usaremos la función `jarque.bera.test()` disponible en el paquete `tseries`:
```{r jarque bera test}
# Peso
jarque.bera.test(new_data[["weight"]])
```
```{r}
# Altura
jarque.bera.test(new_data[["height"]])
```

En ninguno de los dos casos obtenemos p-valores por debajo de 0.05, por lo que **no podemos rechazar la hipótesis nula** de cada variable de seguir la distribución normal.


## 1c. Búsqueda de outliers para peso y altura

Un outlier es una observación que no se ajusta bien al modelo con el que estamos trabajando. Existen métodos estadísticos para localizarlos, pero el modo más intuitivo cuando trabajamos con pocas dimensiones es representando las observaciones en gráficas:

```{r}
# Construme modelo altura-peso
mod_altura_peso <-lm(new_data[["weight"]] ~ new_data[["height"]])

# Genera grafica
plot(new_data[, c("height", "weight")],
     col = ifelse(new_data$height < 155 & new_data$weight > 70, "red", "black"),
     xlab = "Peso", ylab = "Altura"
)
abline(mod_altura_peso,
       col = "blue")
outlier <- new_data[new_data$height < 155 & new_data$weight > 70,]
text(x = ceiling(outlier$height +1),
     y = ceiling(outlier$weight +1),
     labels = rownames(outlier))
```

Parece haber un correlación positiva entre peso y altura, distribuyéndose las observaciones en la gráfica siguiendo una diagonal más o menos marcada (hemos añadido la línea de regresión en color azul para mayor claridad). Sin embargo observamos un sujeto en la zona superior izquierda, remarcado en rojo, llamativamente alejado del resto. ESto es, para su altura presenta un peso muy superior al que esperamos dentro de la muestra.


Si preferimos utilizar métodos numéricos, podemos estudentizar los resíduos y examinar los mayores de entre ellos (_jacknife or crossvalidated residuals_):

```{r}
stud <- rstudent(mod_altura_peso)
head(sort(abs(stud), decreasing = TRUE))
```

Vemos que la observación con mayor residuo estudentizado coincide con la que habíamos detectado en el gráfico. ¿Pero la clasificaríamos realmente como un outlier? Si calculamos el valor crítico de Bonferroni para $\alpha$ = 0.05:
```{r}
n <- nrow(new_data) # Size
p <- 2              # Dimensions
(vc <- abs(qt(0.05/(n*2), (n-p-1)))) # Critical value (absolute) 
```

Vemos que, efectivamente, el valor absoluto de la observación 126 es mayor que el valor absoluto del valor crítico corregido por Bonferroni y numéricamente lo consideraríamos un outlier.

Si queremos representar este test gráficamente:

```{r}
plot(stud, type = 'h',
     main="Outliers por valor crítico",
     xlab = "Observaciones",
     ylab = "Residuos estudentizados")
abline(h= vc, col = "red")
abline(h = 0)
abline(h = -vc, col = "red")
```

Sin embargo, aunque hayamos definido ese valor como un _outlier_ no sabemos si aparece en la muestra por alguna razón anómala (p.e. error al codificar las medidas) o si realmente ese tipo de valores existen en la población a estudiar, así que no lo eliminaremos. Tampoco hemos comprobado si ese valor único ejerce una influencia desproporcionada en los resultados de la regresión.


## 1d. Réplica de los gráficos A, B, C y D de @chan2006estimating


```{r}
# Grouping by sex
grupo <- as.numeric(as.factor(new_data[["gender"]]))
```

```{r chang graphic function}
## Function that draws graphics similars to those in the Chang paper ##

chang_draw <- function(x, y, datos, xlabel, ylabel){
# Colors
  colors <- c("red", "blue")
# Regression models
LM_male <- lm(y ~ x, data = datos, subset = (gender == "M"))
LM_female <- lm(y ~ x, data = datos, subset =(gender == "F"))
  
  # Scatterplot
plot(y ~ x, data = datos,
     pch = c(1,0)[grupo],
     col = colors[grupo],
     xlab = xlabel,
     ylab = ylabel
     )

# Regression lines
abline(LM_male, col = colors[2])
abline(LM_female, col = colors[1], lty = 2)
# Legend
legend("topleft", rep(c("Female", "Male"), 2), col = colors,
       pch = c(1,0,NA,NA), lty = c(0,0,2, 1), inset = 0.05, bty = 'n',
       cex = 0.8, pt.cex = 0.8)
# R-squared text
legend("bottomright", c(paste("R-squared fem:", round(summary(LM_female)[["r.squared"]],2)),
                        paste("R-squared male:", round(summary(LM_male)[["r.squared"]],2))),
       text.col = colors, inset = 0.05, bty = 'n', cex = 0.8)

# legend("bottomright", legend = c(nrow(data[data$gender == "M",]), nrow(data[data$gender == "F",])))
}
```

```{r draw graphs, fig.height=8, fig.width=8}
# Draw the four graphs from Chang (2011)
attach(new_data)

par(mfrow=c(2,2))
chang_draw(ASC, liver_weight, new_data, xlabel = "Área corporal (metros cuadrados)", ylabel = "Peso calculado del hígado (g)")
chang_draw(weight, liver_weight, new_data, xlabel = "Peso corporal (kg)", ylabel = "Peso calculado del hígado (g)")
chang_draw(height, liver_weight, new_data, xlabel = "Altura corporal (cm)", ylabel = "Peso calculado del hígado (g)")

plot(liver_volume ~ liver_weight, data = new_data, pch = 0, xlab = "Peso calculado del hígado (g)", ylab = "Volumen del hígado (mL)")
# ajuste a la recta de regresion
vol_weight_mod <- lm(liver_volume ~ liver_weight, data = new_data)
abline(vol_weight_mod)
legend("bottomright", paste("R-squared:", round(summary(vol_weight_mod)[["r.squared"]],2)), inset = 0.05, bty = 'n', cex = 0.8)
# Predict volume for weight 1000
lw1000 <- predict(vol_weight_mod, data.frame(liver_weight = 1000))
segments(1000, 0, y1 = lw1000)
segments(0, lw1000, x1 = 1000)
```

Tanto en hombres como mujeres, el área y el peso corporal presentan cierta relación con el peso calculado del hígado, pero débil. La altura corporal está incluso menos correlacionada con el peso calculado del hígado.


## 1e. Comprobar coincidencia y paralelismo de las rectas de la primera figura

Cuando queremos saber si dos rectas son iguales, básicamente nos estamos haciendo la pregunta de si ambas rectas tienen la misma pendiente y el mismo punto de corte con el eje _y_. Esto es, queremos contrastar la siguiente hipótesis nula:
$$
H_0: \beta_{females} = \beta_{males}; \alpha_{females} = \alpha_{males}
$$

Matemáticamente existen varias formas de comprobar la hipótesis, pero aquí utilizaremos una de las más sencillas (con las herramientas de las que disponemos), el **análisis de la covarianza**.

En primer lugar construiremos un modelo de regresión lineal con la variable respuesta _peso calculado_, la variable concomitante _área corporal_ y el factor _género_. Una parte muy importante de este modelo es que vamos a examinar la **interacción** entre el áre corporal y el género:

```{r modelo interaccion area corporal genero}
modelo_area_genero <- lm(liver_weight ~ ASC*gender, data = new_data)
```

Resumen del modelo:
```{r}
summary(modelo_area_genero)
```

Mediante el análisis de la varianza podremos interrogar la significatividad de la interacción entre área y género, y averiguar por tanto si los valores para ambas rectas son estadísticamente diferentes:
```{r}
anova(modelo_area_genero)
```

Vemos en la tabla que el contraste ASC:gender (área:género) no es significativo para un nivel de significatividad del 5%, y por tanto no tenemos razones para rechazar la hipótesis nula de igualdad de pendientes. Esto es, concluimos que **las rectas de regresión para hembras y machos son paralelas**.

El contraste que nos permite interrogar la diferencia entre los términos independientes de ambas rectas es el contraste de la variable _gender_, que no es significativo para un nivel de significatividad del 5%. Eso significa que no tenemos razones para rechazar la hipótesis nula de igualdad del punto de intercepción con el eje de ordenadas. Esto es, concluimos que **ambas rectas intersectan con el eje _y_ en el mismo punto**.

Dado que consideramos que ambas rectas tienen la misma pendiente y el mismo punto de intersección con el eje _y_, **no rechazamos la hipótesis de que se trata de la misma recta en los dos grupos**.


## 1e. Regresión múltiple

**Variable respuesta:** Peso estimado del hígado (_liver_weight_).

**Variables regresoras:** Género, peso, altura, ASC (BSA) e IMC (BMI).

Vamos a utilizar R para generar el siguiente modelo lineal:
$$
\text{PESO CALCULADO} = \beta_0 + \beta_{1}\text{GÉNERO} + \beta_{2}\text{PESO} + \beta_{3}\text{ALTURA} + \beta_{4}\text{ASC} + \beta_{5}\text{IMC}
$$

```{r}
# Ajuste a modelo multivariante
mod_multiple <- lm(liver_weight ~ gender + weight + height + ASC + IMC, data = new_data)
summary(mod_multiple)
```

La fórmula que define el plano estimado es (redondeando los coeficientes al segundo dígito significativo):
$$
\hat y = 3050 + 50x_{género} + 39x_{peso} - 17x_{altura} - 68x_{ASC} - 67x_{IMC}
$$

Sin embargo, el coeficiente de determinación ajustado R^2 = `r round(summary(mod_multiple)[["adj.r.squared"]], digits = 2)` nos informa de que el modelo está lejos de ser perfecto a la hora de explicar la variación (o de predecir) de la variable respuesta.


### Análisis de los residuos

Los modelos estadísticos y las pruebas que los contrastan se basan en una serie de asunciones acerca de los datos de origen. Cuando más se aparten los datos de dichas asunciones menos fiables serán las conclusiones a las que lleguemos. El análisis de los residuos nos permite chequear si dichas asunciones se cumplen en los datos con los que estamos trabajando.

#### Comprobación de la homocedasticidad (varianza constante)

Necesitamos saber si la varianza se mantiene constante independientemente de los valores que adopten las variables regresoras. Esto lo podemos investigar representando el valor absoluto de los residuos frente a los valores esperados de la variable respuesta:

```{r}
plot(fitted(mod_multiple), abs(residuals(mod_multiple)),
     xlab = "Valores esperados", ylab = "Residuos (valor absoluto)")
abline(lm(abs(residuals(mod_multiple)) ~ fitted(mod_multiple)),
       col = "blue")
```

Diría que la varianza aumenta para valores esperados mayores, pero para asegurarnos podríamos ajustar los puntos del gráfico a un modelo de regresión y comprobar si la pendiente de la recta es estadísticamente significativa (nivel de significatividad del 5%):

```{r}
summary(lm(abs(residuals(mod_multiple)) ~ fitted(mod_multiple)))
```

Efectivamente, el p-valor de la pendiente nos permite rechazar la hipótesis nula de que la pendiente es 0. Por tanto, llegamos a la conclusión de que la varianza no es constante para todos los valores esperados, sino que es mayor cuanto mayores son dichos valores.


#### Normalidad

Otra asunción es que los residuos siguen la distribución normal. Una manera típica de comprobarlo es mediante su representación en una gráfica Q-Q ó mediante el test de Shapiro-Wilk:
```{r}
qqnorm(residuals(mod_multiple), ylab = "Residuos", xlab = "Cuantiles")
qqline(residuals(mod_multiple))
```

Los residuos parecen apartarse de la distribución normal en los cuantiles más altos.

```{r}
shapiro.test(residuals(mod_multiple))
```

Y, efectivamente, el test de Shapiro-wilk nos anima a rechazar la hipótesis de que la distribución de los residuos es igual a la distribución normal.


#### Leverage

Otra comprobación que podemos hacer es la de la existencia de residuos con valores muy alejados de la media que tienen el potencial de influir excesivamente en el ajuste de valores al modelo. Podemos hacer una búsqueda gráfica de los mismos:

```{r}
hat_mod <- hatvalues(mod_multiple)
p <- length(mod_multiple$coefficients)
n <- length(mod_multiple$fitted.values)
leverage_mean <- p/n


plot(hat_mod, type = 'h')
abline(h=2*leverage_mean, col = "red")
```

La regla general para identificar a ojo los valores con potencialmente excesivo leverage, es que superen en más del doble la media del _leverage_ de todas las observaciones (en la gráfica señalado con una línea roja). En nuestro set de datos, esas observaciones son:
```{r}
names(which(hat_mod > 2*leverage_mean))
```

Una vez localizadas esas observaciones podremos que decidir qué hacer con ellas, si algo hacemos.


#### Valores atípicos

Los valores atípicos son puntos que no se ajustan bien al modelo y que podrían afectar al ajuste del resto de valores. Para detectar estadísticamente estos valores, un método es estudentizar los residuos y comprobar que se adapten a una distribución _t_.

```{r}
estudentizados <- rstudent(mod_multiple)
limites <- abs(qt(0.05/n*2, n-p-2))

plot(estudentizados, type = 'h')
abline(h=limites, col="red"); abline(h=0); abline(h=-limites, col = "red")
```

Sólo encontramos un par de valores atípicos, que podemos identificar de esta forma:
```{r}
names(which(abs(estudentizados) > limites))
```

Una vez identificadas las observaciones que consideramos valores atípicos podemos examinarlas, intentar encontrar una razón por la que presentan valores extremos, y decidir qué hacer al respecto; si algo hacemos.


#### Observaciones influyentes

Los puntos influyentes son aquellos que, si los eliminásemos del set de datos, provocarían un gran cambio en el ajuste. Puede coincidir que sean valores atípicos, o que tengan un leverage alto, pero no necesariamente. Existen diferentes medidas de influencia; en esta ocasión usaremos la distancia de Cook y la representaremos frente a los cuartiles de una distribución seminormal:

```{r}
cook <- cooks.distance(mod_multiple)
halfnorm(cook, nlab = 4, ylab = "Distancias de Cook")
```

En este gráfico hemos identificado los residuos con mayor distancia de Cook pero, ¿cómo decidimos cuáles son (excesivamente) influyentes? Un posible criterio consiste en identificar aquellos con una distancia de Cook que sobrepase el valor crítico $4/n-k-1$:

```{r}
plot(mod_multiple, which = 4)
# p - 2 because p = k + 1
abline(h=4/(n-p-2), col = "red")
```

Si queremos identificarlos a todos:

```{r}
names(which(cook > 4/(n-p-2)))
```

También podemos resumir la situación en un único gráfico:

```{r, fig.cap="Gráfico de influencia sobre la regresión. El área de los círculos es proporcional al valor de la distancia de Cook. Las líneas verticales representan valores dos y tres veces superiores a la media del valor hat. Las líneas horizontales marcan el origen y los valores 2 y -2 de la escala de residuos estudentizados."}
influencePlot(mod_multiple, 
              xlab = "Valores hat", ylab = "Residuos estudentizados")
```

En este gráfico apreciamos que de los cuatro puntos con mayor distancia de Cook, dos de ellos tienen los mayores valores hat y los otros dos tienen valores residuales extremadamente grandes.


#### Estructura del modelo

El estudio de los residuos también puede ayudar a detectar deficiencias en la parte estructural del modelo. Existen múltiples formas de afrontar estas comprobaciones, generalmente de forma gráfica como la representación de residuos frente a *x_i* o frente a $\hat y$ (como ya hicimos anteriormente al comprobar la homocedasticidad).

Para esta sección informe nos decantaremos por el uso de gráficas de _regresión parcial_ como las explicadas en Faraway (2011), que consisten en representar los residuos resultantes de hacer regresión de _y_ sobre todas _x_ excepto *x_i*, frente a los residuos de hacer la regresión de *x_i* frente a todo _x_ excepto *x_i*. Esperamos que los gráficos resultantes no muestren ninguna estructura remarcable.

Debido a constricciones de tiempo, no investigaremos todas las variables regresoras, sino que a modo de ejemplo nos limitaremos a estudiar la regresión parcial de la variable peso ( _weight_ ):

```{r}
# Partial regressions
partial_yx <- residuals(lm(liver_weight ~ . - weight, new_data))
partial_xx <- residuals(lm(weight ~ . - weight, new_data))
plot(partial_xx , partial_yx,
     xlab = "Residuos de peso corporal", ylab = "Residuos de peso calculado del hígado")
abline(lm(partial_yx ~ partial_xx), col="blue")
```

Como esperado, nada reseñable. La distribución de puntos incluso parece aproximada a la de una normal bivariante, y si ajustamos una recta de regresión, esta presenta pendiente cero.


### Multicolinearidad

La multicolinearidad ocurre cuando dos o más variables regresoras (en un modelo de regresión múltiple) están relacionadas linealmente, de forma que cambios en una variable afectan a otra variable de forma predecible. Esta propiedad del set de datos afecta al análisis de cada variable regresora individual (p.e. para comprobar qué variables afectan a la precisión del modelo).

Sospechamos que en nuestro set de datos puede haber multicolinearidad, porque las variables _ASC_ e _IMC_ están calculadas a partir del peso y la altura de cada individuo. Además, las variables peso y altura (como vimos en el gráfico del apartado 1c) también parecen estar relacionadas entre sí al menos de forma parcial.

Una forma de detectar la multicolinearidad es mediante los llamados factores de inflación de la varianza (FIV), que son los elementos de la diagonal de la inversa de la matriz de correlaciones entre variables. Al comparar en FIV de una variable con el R^2 de dicha variable estamos midiendo el incremento en la varianza de los estimadores regresión comparada con el valor que debería tener la varianza si las variables no estuvieran relacionadas.

$$
\text{FIV}_j = (1 - R^2_j)^{-1}
$$

En el caso de nuestro set de datos:
```{r}
# We select all columns except the first
# because it is a categorical one
diag(solve(cor(new_data[, -1])))
```

Según autores, se considera que los datos presentan un problema de multicolinearidad cuando los FIVs tienen valores por encima de 5 ó 10. En nuestro caso se diría que sí **tenemos un problema de multicolinearidad**. Y grande.

Por comparar, vamos a calcular los FIVs para la matriz de datos sin las variables _ASC_ e _IMC_:

```{r}
# We select all columns except the first
# because it is a categorical one
diag(solve(cor(data[, -1])))
```

Si decidimos poner el límite en FIV = 10, o si utilizamos la media de todos los FIV (`r mean(diag(solve(cor(data[, -1])))) `), diríamos que en este set de datos **sin _ASC_ ni _IMC_ no tenemos problemas de multicolinearidad importantes**.


## Contrastar un modelo más simple

Como el modelo propuesto por el grupo de Chan se puede interpretar como un modelo anidado en el modelo general, podemos contrastar si ambos modelos son diferentes mediante un ANOVA. Tomemos como hipótesis nula:
$$
H_0 = \beta_{altura} = \beta_{volumen\ calculado\ del\ hígado} = \beta_{BSA} = \beta_{IMC} = 0 
$$

Generamos ambos modelos y lo ajustamos a la recta:
```{r modelo completo}
mod_completo <- lm(liver_weight ~ ., data = new_data)
sumary(mod_completo)
```



```{r modelo Chan}
mod_Chan <- lm(liver_weight ~ gender + weight, data = new_data)
sumary(mod_Chan)
```

Contrastamos ambos modelos mediante ANOVA:
```{r}
anova(mod_completo, mod_Chan)
```

Según el contraste, tenemos razones para rechazar la hipótesis nula y concluir que tener en cuenta sólo género y peso no es suficiente. Sin embargo, esto en con las variables que nosotros hemos estado usando en este informe. Según el artículo de Chan, el modelo completo que ellos contrastan es este:
$$
\text{PESO CALCULADO} = \beta_0 + \beta_{1}\text{GÉNERO} + \beta_{2}\text{PESO} + \beta_{3}\text{ALTURA}
$$

Y la hipótesis nula para el modelo simplificado:
$$
H_0: \beta_{altura} = 0
$$

Si hacemos el contraste con el nuevo modelo general:
```{r}
mod_completo2 <- lm(liver_weight ~ gender + weight + height, data = new_data)

anova(mod_Chan, mod_completo2)
```

En esta ocasión vemos en el resultado del contraste que no tenemos razones para rechazar la hipótesis nula de que el valor de la variable altura no afecta a la predicción del peso calculado del hígado. Por tanto, podemos utilizar el modelo simplificado que sólo tiene en cuenta género y peso.

#### Estimación del intervalo para la media con nuestro modelo completo

Teniendo en cuenta una donante de 54kg, y que el resto de sus parámetros estén dentro de la media de nuestro set de datos:
```{r}
# Estimacion datos donante
donante <- data.frame(t(colMeans(new_data[-1])))
donante["gender"] <- as.factor("F")
donante["weight"] <- 54

(predi_completo <- predict(mod_multiple, donante, interval = "prediction"))
```

Nuestro modelo completo predice un peso calculado del hígado de `r round(predi_completo[[1]])` gramos, con un intervalo de confianza del 95% entre `r round(predi_completo[[2]])` gramos y `r round(predi_completo[[3]])` gramos.

#### Estimación puntual con el modelo de Chan
```{r}
# Teniendo en cuenta una donante de 54kg
(predi_chan <- predict(mod_Chan, donante))
```

La predicción puntual usando el modelo simplificado de Chan para una donante de 54 kg es un peso calculado de hígado de `r round(predi_chan[[1]])` gramos.


# Ejercicio 2. Habituación y serpientes

### 2a. Datos

Primeramente registraremos los datos en un formato con el que podamos trabajar en R, y que además nos resulte cómodo para análisis posteriores (formato largo).
```{r}
snake_ID <- rep(c("D1", "D3", "D5", "D8", "De", "Dt"), 4)
Day <- rep(c("Day_1", "Day_2", "Day_3", "Day_4"), each = 6)
Day_1 <- c(85, 107, 61, 22, 40, 65)
Day_2 <- c(58, 51, 60, 41, 45, 27)
Day_3 <- c(15, 30, 68, 63, 28, 3)
Day_4 <- c(57, 12, 36, 21, 10, 16)
Trials <- c(Day_1, Day_2, Day_3, Day_4)

snakes_long <- data.frame(snake_ID, Day, Trials)

head(snakes_long)
```

Diseñamos el modelo lineal en R:
```{r}
mod_snakes <- lm(Trials ~ snake_ID + Day, data = snakes_long)
summary(mod_snakes)
```

### Gráfico de barras
```{r}
n <- 6
# Calculate mean
snek_mean <-
  sapply(split(snakes_long$Trials, snakes_long$Day), mean)
# Calculate SE
snek_se <- sapply(split(snakes_long$Trials, snakes_long$Day), sd) / sqrt(n)
# Calculate CI
alpha <- 0.05
t=qt((1-alpha)/2 + .5, n-1)
snek_ci <- t * snek_se

# Function for error bars
# Adapted from
# https://www.r-graph-gallery.com/4-barplot-with-error-bar.html

errorbar <- function(x, y, upper, lower=upper, length=0.1,...){
  arrows(x,y+upper, x, y-lower, angle=90, code=3, length=length, ...)
}


snek_barplot <- barplot(snek_mean, # ylim will accomodate CI bars
                        ylim = c(0, round(sum(max(snek_ci)+max(snek_mean)), -2)),
                        ylab = "Trials",
                        xlab = "Days")
errorbar(snek_barplot, snek_mean, snek_ci, length = 0)
```


## 2b. Rango de la matriz de diseño
```{r}
# Extract design matrix from model
design_matrix <- model.matrix(mod_snakes)
DayDay_1 <- c(rep(1, 6), rep(0, 18))
snake_IDD1 <- rep(c(1,0,0,0,0,0), 4)
design_matrix <- cbind(DayDay_1, snake_IDD1, design_matrix)
(design_matrix <- design_matrix[, c(3, 1, 4:6, 2, 7:11)])
```

### Calcular el rango de la matriz de diseño

Para calcular el rango de la matriz usaré la descomposición QR:
```{r}
qr(design_matrix)$rank
```

**El rango de la matriz de diseño es 9**. Podemos ver que, efectivamente, la suma de las columnas 2 a 5 da como resultado la columna 1; y asimismo, la suma de las columnas 6 a la 11 también da como resultado la primera columna.

Una matriz es de rango máximo cuando el rango es igual al número de parámatros (columnas). En este caso, **la matriz no es de rango máximo**. Eso conlleva el problema de que el sistema de ecuaciones normales que se desprende de la matriz tiene infinitas soluciones, con lo que no se puede identificar el valor estimado de los coeficientes de las variables del modelo. En este caso probablemente se deba a que contamos con más parámetros (11) que observaciones.


## 2c. Calcular una solución de las ecuaciones normales con la matriz g-inversa de Moore-Penrose

La inversa generalizada (g-inverse) de Moore-Penrose es una generalización de la matriz inversa que se usa para calcular la solución que mejor se ajuste a un sistema de ecuaciones lineales que carece de una solución única.

Nuestro problema en notación matricial:
$$
\mathbf{(A'A)^{-1}x = A'b}
$$
Donde **A** es la matriz de diseño, **x** son parámetros, y **b** es el vector de la variable respuesta _Trials_.

Queremos conocer **x**:
$$
\mathbf{x = A'b(A'A)^-}
$$


En el lenguaje R podemos hacer el cálculo mediante la función `ginv()` del paquete `MASS`:
```{r}
# Calcular el vector de coeficientes
A <- design_matrix
(x <- ginv(t(A) %*% A) %*% t(A) %*% Trials)
```

### Cantidad de g-inversas y de soluciones a las ecuaciones normales de este modelo

Recordemos que esta es sólo una de las soluciones posibles. Las inversas no generalizadas por lo general no son únicas, excepto cuando la matriz es no singular. Sin embargo, en el caso de la inversa de Moore-Penrose esta sí que es única para cada sistema de ecuaciones, por lo que este sistema de ecuaciones, resuelto usando la inversa de Moore-Penrose tiene una sola solución, aunque podríamos encontrar otras soluciones usando diferentes métodos para buscar inversas no generalizadas.


### Solución con la función lm() de R

Como ya vimos en el apartado 2a, los coeficientes calculados por la función `lm()` son:
```{r}
coef(mod_snakes)
```

Observamos que la función `lm()` ha eliminado los parámetros _Day1_ y _D2_ para generar una matriz de diseño de rango máximo y solución definida. Vemos también que los valores de los coeficientes aquí calculados no se parecen a los que hemos calculado mediante g-inversa.





# Ejercicio 3. Prueba de aditividad de Tukey

## 3a. Estimar los parámetros del modelo sin interacción

```{r}
# Grand mean
mu <- mean(Trials)
# Marginal snake means
marginal_snake <- sapply(split(snakes_long$Trials, snakes_long$snake_ID), mean)
# Marginal day means
marginal_day <- snek_mean

# Alfa
alfa <- marginal_snake - mu
# Beta
beta <- marginal_day - mu
```

$\hat \mu$ = `r round(mu)`

$\hat \alpha$ =
```{r}
round(alfa)
```

$\hat \beta$ =
```{r}
round(beta)
```



## 3b. Contrastar la no interacción.






<!-- # Apéndice A: Código -->

<!-- El documento original en formato .Rmd, que incluye el código completo en lenguaje R usado para generar este informe, se puede consultar y descargar en el siguiente repositorio de Github: -->
<!-- [jorgevallejo/RNAseq_analysis_PEC2](https://github.com/jorgevallejo/RNAseq_analysis_PEC2) -->

<!-- # Apéndice B: Reproducibilidad {#apendiceB} -->
<!-- ```{r session_info, include=TRUE, echo=TRUE, results='markup'} -->
<!-- sessionInfo() # For better reproducibility -->
<!-- ``` -->


# Referencias